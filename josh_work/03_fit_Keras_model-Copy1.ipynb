{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import Flatten\n",
    "# from tensorflow.keras.layers import Embedding\n",
    "# from tensorflow.keras.layers import Conv1D\n",
    "# from tensorflow.keras.layers import MaxPooling1D\n",
    "# from tensorflow.keras import optimizers\n",
    "# from keras.utils import np_utils\n",
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>event</th>\n",
       "      <th>text_edit</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>57YOM WITH CONTUSION TO FACE AFTER STRIKING IT...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>[contus, face, strike, post, pounder, set, fen...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A 45YOM FELL ON ARM WHILE WORKING HAD SLIPPED ...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>[fell, arm, work, slip, water, fx, wrist]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>58YOM WITH CERVICAL STRAIN  BACK PAIN S P REST...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>[cervic, strain, back, pain, p, restrain, taxi...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33 YOM LAC TO HAND FROM A RAZOR KNIFE</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>[lac, hand, razor, knife]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>53YOM AT WORK IN A WAREHOUSE DOING UNSPECIFIED...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>71</td>\n",
       "      <td>[work, warehous, unspecifi, lift, strain, lo, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sex  age  event  \\\n",
       "0  57YOM WITH CONTUSION TO FACE AFTER STRIKING IT...    1   57     62   \n",
       "1  A 45YOM FELL ON ARM WHILE WORKING HAD SLIPPED ...    1   45     42   \n",
       "2  58YOM WITH CERVICAL STRAIN  BACK PAIN S P REST...    1   58     26   \n",
       "3              33 YOM LAC TO HAND FROM A RAZOR KNIFE    1   33     60   \n",
       "4  53YOM AT WORK IN A WAREHOUSE DOING UNSPECIFIED...    1   53     71   \n",
       "\n",
       "                                           text_edit  token_len  \n",
       "0  [contus, face, strike, post, pounder, set, fen...          8  \n",
       "1          [fell, arm, work, slip, water, fx, wrist]          7  \n",
       "2  [cervic, strain, back, pain, p, restrain, taxi...         16  \n",
       "3                          [lac, hand, razor, knife]          4  \n",
       "4  [work, warehous, unspecifi, lift, strain, lo, ...          8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/tokenized.pkl')\n",
    "df['text_edit'] = df['text_edit'].apply(list)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create reference vocabulary used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = set()\n",
    "# for _,e in df['text_edit'].iteritems():\n",
    "#     vocab = vocab.union(set(e))\n",
    "#\n",
    "# len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Keras that fits the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine maximum token sequence length for training. We don't want to simply use that max as reviews 20 or longer are rare. Based on distribution below we select a max length of 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         3\n",
       "2         4\n",
       "3       465\n",
       "4      2050\n",
       "5      5694\n",
       "6      9954\n",
       "7     13875\n",
       "8     16838\n",
       "9     17009\n",
       "10    16252\n",
       "11    14736\n",
       "12    13000\n",
       "13    10920\n",
       "14     9344\n",
       "15     7513\n",
       "16     5979\n",
       "17     4335\n",
       "18     2870\n",
       "19     1641\n",
       "20      835\n",
       "21      369\n",
       "22      179\n",
       "23       66\n",
       "24       14\n",
       "25        8\n",
       "26        2\n",
       "28        1\n",
       "Name: token_len, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_len'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df['text_edit'].str[:max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18, 45, 257, 453, 3850, 844, 382, 453],\n",
       " [7, 32, 1, 34, 165, 38, 28],\n",
       " [209, 10, 6, 3, 23, 154, 902, 117, 31, 765, 442, 355, 206, 90, 519]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_doc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pad_sequences(encoded_doc, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   45,  257,  453, 3850,  844,  382,  453,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# we add +1 to account for missing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create target matrix.  \n",
    "As this is a multi-class model keras requires the target to be in the form of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(df['event'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yencoded = encoder.fit_transform(df['event'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform([42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np_utils.to_categorical(yencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_size = len(np.unique(yencoded))\n",
    "target_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 1, input_length=max_len))\n",
    "# model.add(Conv1D(filters=1, kernel_size=2, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1, activation='relu'))\n",
    "# model.add(Dense(target_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(target_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 15, 100)           2684500   \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 8, 32)             25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 48)                4848      \n",
      "=================================================================\n",
      "Total params: 2,727,880\n",
      "Trainable params: 2,727,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123164 samples, validate on 30792 samples\n",
      "Epoch 1/10\n",
      "123164/123164 [==============================] - 19s 150us/step - loss: 1.8503 - acc: 0.4781 - val_loss: 1.1337 - val_acc: 0.6716\n",
      "Epoch 2/10\n",
      "123164/123164 [==============================] - 18s 144us/step - loss: 0.9606 - acc: 0.7214 - val_loss: 0.8694 - val_acc: 0.7442\n",
      "Epoch 3/10\n",
      "123164/123164 [==============================] - 18s 145us/step - loss: 0.7785 - acc: 0.7678 - val_loss: 0.7802 - val_acc: 0.7658\n",
      "Epoch 4/10\n",
      "123164/123164 [==============================] - 18s 144us/step - loss: 0.6817 - acc: 0.7936 - val_loss: 0.7336 - val_acc: 0.7771\n",
      "Epoch 5/10\n",
      "123164/123164 [==============================] - 18s 145us/step - loss: 0.6157 - acc: 0.8117 - val_loss: 0.7085 - val_acc: 0.7856\n",
      "Epoch 6/10\n",
      "123164/123164 [==============================] - 18s 144us/step - loss: 0.5663 - acc: 0.8265 - val_loss: 0.6905 - val_acc: 0.7907\n",
      "Epoch 7/10\n",
      "123164/123164 [==============================] - 18s 144us/step - loss: 0.5264 - acc: 0.8387 - val_loss: 0.6823 - val_acc: 0.7920\n",
      "Epoch 8/10\n",
      "123164/123164 [==============================] - 18s 145us/step - loss: 0.4928 - acc: 0.8482 - val_loss: 0.6785 - val_acc: 0.7944\n",
      "Epoch 9/10\n",
      "123164/123164 [==============================] - 18s 145us/step - loss: 0.4632 - acc: 0.8571 - val_loss: 0.6803 - val_acc: 0.7953\n",
      "Epoch 10/10\n",
      "123164/123164 [==============================] - 18s 145us/step - loss: 0.4365 - acc: 0.8654 - val_loss: 0.6832 - val_acc: 0.7944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8372c90850>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=10, verbose=1, validation_split=.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123164 samples, validate on 30792 samples\n",
      "Epoch 1/10\n",
      "123164/123164 [==============================] - 36s 293us/step - loss: 1.5824 - acc: 0.5475 - val_loss: 0.9696 - val_acc: 0.7208\n",
      "Epoch 2/10\n",
      "123164/123164 [==============================] - 35s 286us/step - loss: 0.8506 - acc: 0.7515 - val_loss: 0.8112 - val_acc: 0.7594\n",
      "Epoch 3/10\n",
      "123164/123164 [==============================] - 35s 286us/step - loss: 0.7100 - acc: 0.7863 - val_loss: 0.7352 - val_acc: 0.7788\n",
      "Epoch 4/10\n",
      "123164/123164 [==============================] - 35s 285us/step - loss: 0.6289 - acc: 0.8072 - val_loss: 0.7020 - val_acc: 0.7874\n",
      "Epoch 5/10\n",
      "123164/123164 [==============================] - 35s 285us/step - loss: 0.5711 - acc: 0.8245 - val_loss: 0.6877 - val_acc: 0.7893\n",
      "Epoch 6/10\n",
      "123164/123164 [==============================] - 35s 285us/step - loss: 0.5261 - acc: 0.8358 - val_loss: 0.6740 - val_acc: 0.7933\n",
      "Epoch 7/10\n",
      "123164/123164 [==============================] - 35s 286us/step - loss: 0.4873 - acc: 0.8478 - val_loss: 0.6674 - val_acc: 0.7942\n",
      "Epoch 8/10\n",
      "123164/123164 [==============================] - 35s 284us/step - loss: 0.4538 - acc: 0.8583 - val_loss: 0.6654 - val_acc: 0.7980\n",
      "Epoch 9/10\n",
      "123164/123164 [==============================] - 35s 284us/step - loss: 0.4233 - acc: 0.8670 - val_loss: 0.6716 - val_acc: 0.7958\n",
      "Epoch 10/10\n",
      "123164/123164 [==============================] - 35s 285us/step - loss: 0.3949 - acc: 0.8758 - val_loss: 0.6747 - val_acc: 0.7978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8372b46f10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=10, verbose=1, validation_split=.2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123164 samples, validate on 30792 samples\n",
      "Epoch 1/10\n",
      "123164/123164 [==============================] - 5s 45us/step - loss: 1.1232 - acc: 0.6727 - val_loss: 0.7284 - val_acc: 0.7780\n",
      "Epoch 2/10\n",
      "123164/123164 [==============================] - 5s 37us/step - loss: 0.6022 - acc: 0.8120 - val_loss: 0.6580 - val_acc: 0.7960\n",
      "Epoch 3/10\n",
      "123164/123164 [==============================] - 5s 37us/step - loss: 0.4700 - acc: 0.8505 - val_loss: 0.6664 - val_acc: 0.7954\n",
      "Epoch 4/10\n",
      "123164/123164 [==============================] - 4s 36us/step - loss: 0.3794 - acc: 0.8785 - val_loss: 0.6934 - val_acc: 0.7962\n",
      "Epoch 5/10\n",
      "123164/123164 [==============================] - 5s 37us/step - loss: 0.3095 - acc: 0.9009 - val_loss: 0.7501 - val_acc: 0.7904\n",
      "Epoch 6/10\n",
      "123164/123164 [==============================] - 4s 36us/step - loss: 0.2528 - acc: 0.9184 - val_loss: 0.7925 - val_acc: 0.7875\n",
      "Epoch 7/10\n",
      "123164/123164 [==============================] - 5s 37us/step - loss: 0.2071 - acc: 0.9329 - val_loss: 0.8813 - val_acc: 0.7820\n",
      "Epoch 8/10\n",
      "123164/123164 [==============================] - 5s 37us/step - loss: 0.1723 - acc: 0.9436 - val_loss: 0.9619 - val_acc: 0.7747\n",
      "Epoch 9/10\n",
      "123164/123164 [==============================] - 4s 36us/step - loss: 0.1446 - acc: 0.9527 - val_loss: 1.0497 - val_acc: 0.7733\n",
      "Epoch 10/10\n",
      "123164/123164 [==============================] - 4s 36us/step - loss: 0.1211 - acc: 0.9605 - val_loss: 1.1281 - val_acc: 0.7675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f831d8e4bd0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=10, verbose=1, validation_split=.2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0005), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123164 samples, validate on 30792 samples\n",
      "Epoch 1/2\n",
      "123164/123164 [==============================] - 17s 139us/step - loss: 0.5750 - acc: 0.8216 - val_loss: 0.7054 - val_acc: 0.7885\n",
      "Epoch 2/2\n",
      "123164/123164 [==============================] - 17s 136us/step - loss: 0.4716 - acc: 0.8504 - val_loss: 0.6966 - val_acc: 0.7923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f832c3e3f90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=2,verbose=1,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123164 samples, validate on 30792 samples\n",
      "Epoch 1/5\n",
      "123164/123164 [==============================] - 3s 21us/step - loss: 0.3410 - acc: 0.8946 - val_loss: 0.6832 - val_acc: 0.7992\n",
      "Epoch 2/5\n",
      "123164/123164 [==============================] - 2s 18us/step - loss: 0.3216 - acc: 0.9004 - val_loss: 0.6890 - val_acc: 0.7998\n",
      "Epoch 3/5\n",
      "123164/123164 [==============================] - 2s 18us/step - loss: 0.3089 - acc: 0.9047 - val_loss: 0.6975 - val_acc: 0.7984\n",
      "Epoch 4/5\n",
      "123164/123164 [==============================] - 2s 18us/step - loss: 0.2981 - acc: 0.9078 - val_loss: 0.7053 - val_acc: 0.7974\n",
      "Epoch 5/5\n",
      "123164/123164 [==============================] - 2s 18us/step - loss: 0.2888 - acc: 0.9108 - val_loss: 0.7138 - val_acc: 0.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8324734fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=5,verbose=1,validation_split=.2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153956,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob = model.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yprob[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = yprob.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   act  pred\n",
       "0   33    33\n",
       "1   18    18\n",
       "2   10    10\n",
       "3   31    31\n",
       "4   41    41"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = pd.DataFrame(data=np.column_stack([ytrain.argmax(1),ypred]),columns=['act','pred'])\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(dfres['act'],dfres['pred']).to_excel('./results/crosstab_accuracy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799721998493076"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dfres['act'] == dfres['pred'])/dfres.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8935</td>\n",
       "      <td>9832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2236</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3256</td>\n",
       "      <td>3272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>283</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1016</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>97</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2691</td>\n",
       "      <td>2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>844</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>902</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>330</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1512</td>\n",
       "      <td>1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15624</td>\n",
       "      <td>15543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6549</td>\n",
       "      <td>6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>372</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>496</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>474</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3897</td>\n",
       "      <td>3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11672</td>\n",
       "      <td>11614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8982</td>\n",
       "      <td>8237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24402</td>\n",
       "      <td>23886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9058</td>\n",
       "      <td>9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4381</td>\n",
       "      <td>4737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>48</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2873</td>\n",
       "      <td>3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5315</td>\n",
       "      <td>5355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25910</td>\n",
       "      <td>26395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>764</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8314</td>\n",
       "      <td>9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>888</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1373</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      act   pred\n",
       "0       2       \n",
       "1    8935   9832\n",
       "2    2236   1343\n",
       "3    3256   3272\n",
       "4      12       \n",
       "5      36      2\n",
       "6      50       \n",
       "7     283    305\n",
       "8    1016    956\n",
       "9      97     52\n",
       "10   2691   2782\n",
       "11    844    672\n",
       "12      1       \n",
       "13      1       \n",
       "14    902    906\n",
       "15    330    320\n",
       "16     50       \n",
       "17   1512   1395\n",
       "18  15624  15543\n",
       "19   6549   6676\n",
       "20    372    350\n",
       "21     14       \n",
       "22     26       \n",
       "23     26       \n",
       "24    496    492\n",
       "25    474    480\n",
       "26   3897   3965\n",
       "27     10       \n",
       "28  11672  11614\n",
       "29      6       \n",
       "30      4       \n",
       "31   8982   8237\n",
       "32     52       \n",
       "33  24402  23886\n",
       "34   9058   9789\n",
       "35   4381   4737\n",
       "36     48       \n",
       "37   2873   3085\n",
       "38     60     11\n",
       "39     96      9\n",
       "40   5315   5355\n",
       "41  25910  26395\n",
       "42    764    811\n",
       "43   8314   9022\n",
       "44      4       \n",
       "45    888    676\n",
       "46     12       \n",
       "47   1373    986"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dfres['act'].value_counts(),dfres['pred'].value_counts()],1).sort_index().fillna('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on all data instead of using a validation set\n",
    "Based on above fit we will fit 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(target_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 15, 100)           2684500   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 8, 32)             25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 48)                4848      \n",
      "=================================================================\n",
      "Total params: 2,727,880\n",
      "Trainable params: 2,727,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "153956/153956 [==============================] - 306s 2ms/step - loss: 1.6894 - acc: 0.5208\n",
      "Epoch 2/10\n",
      "153956/153956 [==============================] - 310s 2ms/step - loss: 0.9085 - acc: 0.7348\n",
      "Epoch 3/10\n",
      "153956/153956 [==============================] - 316s 2ms/step - loss: 0.7479 - acc: 0.7757\n",
      "Epoch 4/10\n",
      "153956/153956 [==============================] - 276s 2ms/step - loss: 0.6592 - acc: 0.7996\n",
      "Epoch 5/10\n",
      "153956/153956 [==============================] - 304s 2ms/step - loss: 0.5966 - acc: 0.8168\n",
      "Epoch 6/10\n",
      "153956/153956 [==============================] - 284s 2ms/step - loss: 0.5485 - acc: 0.8309\n",
      "Epoch 7/10\n",
      "153956/153956 [==============================] - 282s 2ms/step - loss: 0.5097 - acc: 0.8415\n",
      "Epoch 8/10\n",
      "153956/153956 [==============================] - 295s 2ms/step - loss: 0.4766 - acc: 0.8513\n",
      "Epoch 9/10\n",
      "153956/153956 [==============================] - 328s 2ms/step - loss: 0.4475 - acc: 0.8602\n",
      "Epoch 10/10\n",
      "153956/153956 [==============================] - 316s 2ms/step - loss: 0.4213 - acc: 0.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26752015748>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/keras_try1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
